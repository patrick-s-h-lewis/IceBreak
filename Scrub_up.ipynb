{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from scrapy.http import TextResponse\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def strip_text(data):\n",
    "    #return a list from an html string of the html tags\n",
    "    p = re.compile('<.*?>')\n",
    "    return p.findall(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strip_tags(data):\n",
    "    #strips tags from an html string.\n",
    "    p = re.compile('<.*?>')\n",
    "    return p.sub(\"*\",data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def strip_meta(tags):\n",
    "    #strips metadata (classes, attributes etc) from list of html tags\n",
    "    cleantags = [];\n",
    "    p = re.compile(\"\"\"\\A\\<[a-z | A-Z]*\\ \"\"\")\n",
    "    for tag in tags:\n",
    "        if (tag[1]==\"!\"):\n",
    "            pass\n",
    "        else:\n",
    "            new_tag = p.findall(tag)\n",
    "            if new_tag==[]: cleantags.append(tag)\n",
    "            else: cleantags.append(new_tag[0][:-1]+\">\")\n",
    "    return cleantags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sanitise(raw_tags,codex):\n",
    "    #take tags and replace by an integer alphabet. codex is \"tags3\"\n",
    "    reader = csv.reader(open(codex, 'rb'))\n",
    "    tag_dict= dict((x[0],int(x[1])) for x in reader)\n",
    "    sanitised_list = []\n",
    "    for item in raw_tags:\n",
    "        try:\n",
    "            sanitised = tag_dict[item]\n",
    "            sanitised_list.append(sanitised)\n",
    "        except:\n",
    "            pass\n",
    "    return sanitised_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def layer_search(r):\n",
    "    members = r.xpath(\"*\")\n",
    "    big_layer_size = 0\n",
    "    big_layer_ind = 1\n",
    "    layer_ind = 0\n",
    "    for member in members:\n",
    "        layer_ind+=1\n",
    "        layer_size = len(member.xpath(\"descendant::*\"))\n",
    "        print(\"descendants of node \"+str(layer_ind) +\": \" +str(layer_size))\n",
    "        if (layer_size>big_layer_size):\n",
    "            next_member = member\n",
    "            big_layer_ind=layer_ind\n",
    "            big_layer_size = layer_size\n",
    "    print(\"returning node \"+str(big_layer_ind))\n",
    "    return next_member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def recurse(func,thing,times):\n",
    "    if times ==0: \n",
    "        layer_report_dev(thing)\n",
    "        return thing\n",
    "    else: \n",
    "        layer_report_dev(thing)\n",
    "        return recurse(func, func(thing),times-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def Most_Common(lst):\n",
    "    data = Counter(lst)\n",
    "    return data.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#strike a match algorithm!\n",
    "#http://www.catalysoft.com/articles/StrikeAMatch.html\n",
    "#http://stackoverflow.com/questions/653157/a-better-similarity-ranking-algorithm-for-variable-length-strings\n",
    "def get_bigrams(s):\n",
    "    '''\n",
    "    Takes a string and returns a list of bigrams\n",
    "    '''\n",
    "    return [s[i:i+2] for i in xrange(len(s) - 1)]\n",
    "\n",
    "def string_similarity(str1, str2):\n",
    "    '''\n",
    "    Perform bigram comparison between two strings\n",
    "    and return a percentage match in decimal form\n",
    "    '''\n",
    "    if (str1==\"\" or str2==\"\"): \n",
    "        score = 0.0\n",
    "    else: \n",
    "        pairs1 = get_bigrams(str1)\n",
    "        pairs2 = get_bigrams(str2)\n",
    "        union  = len(pairs1) + len(pairs2)\n",
    "        hit_count = 0\n",
    "        for x in pairs1:\n",
    "            for y in pairs2:\n",
    "                if x == y:\n",
    "                    hit_count += 1\n",
    "                    pairs2.remove(y)\n",
    "                    break\n",
    "        if union == 0:\n",
    "            score = 0.\n",
    "        else: \n",
    "            score = (2.0 * hit_count) / union\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sanitise2(raw_tags,codex):\n",
    "    #take tags and replace by an string character alphabet. codex is \"tags3\"\n",
    "    reader = csv.reader(open(codex, 'rb'))\n",
    "    tag_dict= dict((x[0],x[1]) for x in reader)\n",
    "    sanitised_list = []\n",
    "    for item in raw_tags:\n",
    "        try:\n",
    "            sanitised = tag_dict[item]\n",
    "            sanitised_list.append(sanitised)\n",
    "        except:\n",
    "            pass\n",
    "    return \"\".join(sanitised_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def layer_report(r):\n",
    "    struct_list = []\n",
    "    for mem in r.xpath(\"*\"):\n",
    "        raw_tags = strip_meta(strip_text(mem.extract()))\n",
    "        san = sanitise2(raw_tags,'tags4.csv')\n",
    "        struct_list.append(san)\n",
    "    bench = Most_Common(struct_list)\n",
    "    sim_list = []\n",
    "    for s in struct_list:\n",
    "        sim_list.append(string_similarity(s,bench))\n",
    "    average_similarity = sum(sim_list)/len(sim_list)\n",
    "    number = len(r.xpath(\"*\"))\n",
    "    qualifying_records = sum([similarity_threshold<=x<=1 for x in sim_list])\n",
    "    proportion = sum([similarity_threshold<=x<=1 for x in sim_list])/float(number)\n",
    "    print(\"average similarity is: \" + str(average_similarity))\n",
    "    print(\"number of nodes is: \" + str(number))\n",
    "    print(\"number of qualifying records: \"+str(qualifying_records))\n",
    "    print(\"proportion of similar records: \" + str(proportion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make a function that counts descendents. This will simplify greatly.\n",
    "#for each member in a member \"layer\" list, get their counts. Don't imediately take the longest. \n",
    "#Look at them and see if most of them are about the same size. If they are, we have likely found the repeating unit\n",
    "#if not, we need to go down into the most \"descendent heavy\" member and continue. \n",
    "\n",
    "#if the number of nodes is \"large\" \n",
    "#and the descendents of the nodes is \"similar\"\n",
    "#STRUCTURE OF THE NODES have common repeating substrings...\n",
    "#These three should guarenteee the repeat unit has been found. \n",
    "\n",
    "#plan shaping up:\n",
    "#1: get most commonly occuring one\n",
    "#2: process members into their encoded letters by structure\n",
    "#3: rank their similarity to most commonly occuring one\n",
    "#4: those above a certain threshhold are considered records\n",
    "#5: find shortest and longest records and get then get the records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = requests.get('http://ora.ox.ac.uk/search/detailed?q=%2A%3A%2A&truncate=450&rows=50&sort=timestamp%20desc')\n",
    "response = TextResponse(r.url, body=r.text, encoding='utf-8')\n",
    "body = response.xpath(\"//body\").extract()\n",
    "raw_tags = strip_meta(strip_text(body[0]))\n",
    "san_list = sanitise(raw_tags,'tags2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average similarity is: 0.0\n",
      "number of nodes is: 5\n",
      "number of qualifying records: 0\n",
      "proportion of similar records: 0.0\n",
      "Am I done? : False\n",
      "descendants of node 1: 1988\n",
      "descendants of node 2: 21\n",
      "descendants of node 3: 2\n",
      "descendants of node 4: 0\n",
      "descendants of node 5: 0\n",
      "returning node 1\n",
      "average similarity is: 0.0\n",
      "number of nodes is: 5\n",
      "number of qualifying records: 0\n",
      "proportion of similar records: 0.0\n",
      "Am I done? : False\n",
      "descendants of node 1: 0\n",
      "descendants of node 2: 18\n",
      "descendants of node 3: 1965\n",
      "descendants of node 4: 0\n",
      "descendants of node 5: 0\n",
      "returning node 3\n",
      "average similarity is: 0.56335078534\n",
      "number of nodes is: 2\n",
      "number of qualifying records: 1\n",
      "proportion of similar records: 0.5\n",
      "Am I done? : False\n",
      "descendants of node 1: 1313\n",
      "descendants of node 2: 650\n",
      "returning node 1\n",
      "average similarity is: 0.334932056398\n",
      "number of nodes is: 3\n",
      "number of qualifying records: 1\n",
      "proportion of similar records: 0.333333333333\n",
      "Am I done? : False\n",
      "descendants of node 1: 4\n",
      "descendants of node 2: 10\n",
      "descendants of node 3: 1296\n",
      "returning node 3\n",
      "average similarity is: 0.751784883952\n",
      "number of nodes is: 57\n",
      "number of qualifying records: 50\n",
      "proportion of similar records: 0.877192982456\n",
      "Am I done? : True\n",
      "descendants of node 1: 24\n",
      "descendants of node 2: 8\n",
      "descendants of node 3: 8\n",
      "descendants of node 4: 0\n",
      "descendants of node 5: 20\n",
      "descendants of node 6: 22\n",
      "descendants of node 7: 20\n",
      "descendants of node 8: 21\n",
      "descendants of node 9: 28\n",
      "descendants of node 10: 22\n",
      "descendants of node 11: 28\n",
      "descendants of node 12: 20\n",
      "descendants of node 13: 22\n",
      "descendants of node 14: 21\n",
      "descendants of node 15: 28\n",
      "descendants of node 16: 25\n",
      "descendants of node 17: 25\n",
      "descendants of node 18: 20\n",
      "descendants of node 19: 28\n",
      "descendants of node 20: 28\n",
      "descendants of node 21: 20\n",
      "descendants of node 22: 28\n",
      "descendants of node 23: 28\n",
      "descendants of node 24: 28\n",
      "descendants of node 25: 25\n",
      "descendants of node 26: 25\n",
      "descendants of node 27: 22\n",
      "descendants of node 28: 23\n",
      "descendants of node 29: 20\n",
      "descendants of node 30: 20\n",
      "descendants of node 31: 20\n",
      "descendants of node 32: 20\n",
      "descendants of node 33: 20\n",
      "descendants of node 34: 20\n",
      "descendants of node 35: 21\n",
      "descendants of node 36: 20\n",
      "descendants of node 37: 25\n",
      "descendants of node 38: 30\n",
      "descendants of node 39: 25\n",
      "descendants of node 40: 25\n",
      "descendants of node 41: 22\n",
      "descendants of node 42: 25\n",
      "descendants of node 43: 22\n",
      "descendants of node 44: 21\n",
      "descendants of node 45: 25\n",
      "descendants of node 46: 24\n",
      "descendants of node 47: 23\n",
      "descendants of node 48: 25\n",
      "descendants of node 49: 23\n",
      "descendants of node 50: 25\n",
      "descendants of node 51: 22\n",
      "descendants of node 52: 23\n",
      "descendants of node 53: 25\n",
      "descendants of node 54: 19\n",
      "descendants of node 55: 24\n",
      "descendants of node 56: 8\n",
      "descendants of node 57: 0\n",
      "returning node 38\n",
      "average similarity is: 0.0\n",
      "number of nodes is: 6\n",
      "number of qualifying records: 0\n",
      "proportion of similar records: 0.0\n",
      "Am I done? : False\n",
      "*\n",
      "\n",
      "**\n",
      "**Illuminance flow estimation by regression**\n",
      "**\n",
      "*\n",
      "*\n",
      "*Abstract*\n",
      "\n",
      "**We investigate the estimation of illuminance flow using Histograms of Oriented Gradient features (HOGs). In a regression setting, we found for both ridge regression and support vector machines, that the optimal solution shows close resemblance to the gradient based structure tensor (also known as the second moment matrix).**Theoretical results are presented showing in detail how the structure tensor and the HOGs are connected. This relati ... [truncated at 450 characters in length]**\n",
      "*\n",
      "*\n",
      "*Author**\n",
      "            \t\t\t    \n",
      "Stefan M. Karlsson; \n",
      "                \n",
      "Sylvia C. Pont; \n",
      "                \n",
      "Jan J. Koenderink; \n",
      "                \n",
      "                \n",
      "et al\n",
      "**\n",
      "*\n",
      "*Date*\n",
      "          \n",
      "*2010*\n",
      "*\n",
      "*\n",
      "\n",
      "*\n",
      "*\n",
      "          \n",
      "**Article**\n",
      "*\n",
      "          \n",
      "*\n",
      "****\n",
      "*\n",
      "          \n",
      "*\n",
      "****\n",
      "          \n",
      "**\n",
      "****\n",
      "*\n",
      "*\n",
      "\n",
      "\n",
      "**\n",
      "*\n"
     ]
    }
   ],
   "source": [
    "similarity_threshold = 0.65\n",
    "number_threshold = 50\n",
    "proportion_threshold = 0.80\n",
    "average_similarity_threshold = 0.75\n",
    "b = recurse(layer_search,response.xpath(\"//body\"),5)\n",
    "print(strip_tags(b.extract()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def layer_report_dev(r):\n",
    "    struct_list = []\n",
    "    for mem in r.xpath(\"*\"):\n",
    "        raw_tags = strip_meta(strip_text(mem.extract()))\n",
    "        san = sanitise2(raw_tags,'tags4.csv')\n",
    "        struct_list.append(san)\n",
    "    bench = Most_Common(struct_list)\n",
    "    sim_list = []\n",
    "    for s in struct_list:\n",
    "        sim_list.append(string_similarity(s,bench))\n",
    "    average_similarity = sum(sim_list)/len(sim_list)\n",
    "    number = len(r.xpath(\"*\"))\n",
    "    qualifying_records = sum([similarity_threshold<=x<=1 for x in sim_list])\n",
    "    proportion = sum([similarity_threshold<=x<=1 for x in sim_list])/float(number)\n",
    "    print(\"average similarity is: \" + str(average_similarity))\n",
    "    print(\"number of nodes is: \" + str(number))\n",
    "    print(\"number of qualifying records: \"+str(qualifying_records))\n",
    "    print(\"proportion of similar records: \" + str(proportion))\n",
    "    done = (\n",
    "        (qualifying_records>=number_threshold) and \n",
    "        (proportion>=proportion_threshold) and \n",
    "        (average_similarity>=average_similarity_threshold)\n",
    "    )\n",
    "    print(\"Am I done? : \" + str(done) )\n",
    "    return done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
